sapply(knn_cont, lines)
## do bootstrap to get a sense of variance in decision surface
resample <- function(dat) {
idx <- sample(1:length(dat$y), replace = T)
dat$y <- dat$y[idx]
dat$x <- dat$x[idx,]
return(dat)
}
## plot linear classifier for three bootstraps
par(mfrow=c(1,3))
for(b in 1:3) {
datb <- resample(dat)
## fit model to mixture data and make predictions
lc_beta <- fit_lc(datb$y, datb$x)
lc_pred <- predict_lc(datb$xnew, lc_beta)
## reshape predictions as a matrix
lc_pred <- matrix(lc_pred, length(datb$px1), length(datb$px2))
## find the contours in 2D space such that lc_pred == 0.5
lc_cont <- contourLines(datb$px1, datb$px2, lc_pred, levels=0.5)
## plot data and decision surface
eval(plot_mix_data)
sapply(lc_cont, lines)
}
## plot 5-NN classifier for three bootstraps
par(mfrow=c(1,3))
for(b in 1:3) {
datb <- resample(dat)
knn_fit <- knn(train=datb$x, test=datb$xnew, cl=datb$y, k=5, prob=TRUE)
knn_pred <- attr(knn_fit, 'prob')
knn_pred <- ifelse(knn_fit == 1, knn_pred, 1-knn_pred)
## reshape predictions as a matrix
knn_pred <- matrix(knn_pred, length(datb$px1), length(datb$px2))
## find the contours in 2D space such that knn_pred == 0.5
knn_cont <- contourLines(datb$px1, datb$px2, knn_pred, levels=0.5)
## plot data and decision surface
eval(plot_mix_data)
sapply(knn_cont, lines)
}
## plot 20-NN classifier for three bootstraps
par(mfrow=c(1,3))
for(b in 1:3) {
datb <- resample(dat)
knn_fit <- knn(train=datb$x, test=datb$xnew, cl=datb$y, k=20, prob=TRUE)
knn_pred <- attr(knn_fit, 'prob')
knn_pred <- ifelse(knn_fit == 1, knn_pred, 1-knn_pred)
## reshape predictions as a matrix
knn_pred <- matrix(knn_pred, length(datb$px1), length(datb$px2))
## find the contours in 2D space such that knn_pred == 0.5
knn_cont <- contourLines(datb$px1, datb$px2, knn_pred, levels=0.5)
## plot data and decision surface
eval(plot_mix_data)
sapply(knn_cont, lines)
}
## fit linear classifier
fit_lc_new <- function(y,x){
return(lm(y~I(x^2) + I(x)))
}
## make predictions from linear classifier
predict_lc_new <- function(x, fun) {
cbind(cbind(1, x*x),x) %*% fun$coefficients
}
## fit model to mixture data and make predictions
lc_beta_new <- fit_lc_new(dat$y, dat$x)
lc_pred_new <- predict_lc_new(dat$xnew, lc_beta_new)
## reshape predictions as a matrix
lc_pred_new <- matrix(lc_pred_new, length(dat$px1), length(dat$px2))
contour(lc_pred_new,
xlab=expression(x[1]),
ylab=expression(x[2]))
## find the contours in 2D space such that lc_pred == 0.5
lc_cont_new <- contourLines(dat$px1, dat$px2, lc_pred_new, levels=0.5)
## plot data and decision surface
eval(plot_mix_data)
sapply(lc_cont_new, lines)
## do bootstrap to get a sense of variance in decision surface
resample <- function(dat) {
idx <- sample(1:length(dat$y), replace = T)
dat$y <- dat$y[idx]
dat$x <- dat$x[idx,]
return(dat)
}
## plot linear classifier for three bootstraps
par(mfrow=c(1,3))
for(b in 1:3) {
datb <- resample(dat)
## fit model to mixture data and make predictions
lc_beta_new <- fit_lc_new(datb$y, datb$x)
lc_pred_new <- predict_lc_new(datb$xnew, lc_beta_new)
## reshape predictions as a matrix
lc_pred_new <- matrix(lc_pred_new, length(datb$px1), length(datb$px2))
## find the contours in 2D space such that lc_pred == 0.5
lc_cont_new <- contourLines(datb$px1, datb$px2, lc_pred_new, levels=0.5)
lc_beta <- fit_lc(datb$y, datb$x)
lc_pred <- predict_lc(datb$xnew, lc_beta)
## reshape predictions as a matrix
lc_pred <- matrix(lc_pred, length(datb$px1), length(datb$px2))
## find the contours in 2D space such that lc_pred == 0.5
lc_cont <- contourLines(datb$px1, datb$px2, lc_pred, levels=0.5)
## plot data and decision surface
eval(plot_mix_data)
sapply(lc_cont_new, lines)
sapply(lc_cont, lines)
}
## load prostate data
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
## subset to training examples
prostate_train <- subset(prostate, train==TRUE)
## plot lcavol vs lpsa
plot_psa_data <- function(dat=prostate_train) {
plot(dat$lpsa, dat$lcavol,
xlab="log Prostate Screening Antigen (psa)",
ylab="log Cancer Volume (lcavol)",
pch = 20)
}
plot_psa_data()
############################
## regular linear regression
############################
## L2 loss function
L2_loss <- function(y, yhat)
(y-yhat)^2
## fit simple linear model using numerical optimization
predict_lin <- function(x, beta){
beta[1] + beta[2]*x
}
fit_lin <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta)))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
## make predictions from linear model
## fit linear model
lin_beta <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=L2_loss)
## compute predictions for a grid of inputs
x_grid <- seq(min(prostate_train$lpsa),
max(prostate_train$lpsa),
length.out=100)
lin_pred <- predict_lin(x=x_grid, beta=lin_beta$par)
## plot data
plot_psa_data()
## plot predictions
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
## do the same thing with 'lm'
lin_fit_lm <- lm(lcavol ~ lpsa, data=prostate_train)
## make predictins using 'lm' object
lin_pred_lm <- predict(lin_fit_lm, data.frame(lpsa=x_grid))
## plot predictions from 'lm'
lines(x=x_grid, y=lin_pred_lm, col='pink', lty=2, lwd=2)
##################################
## try modifying the loss function
##################################
## custom loss function
custom_loss <- function(y, yhat)
(y-yhat)^2 + abs(y-yhat)
## plot custom loss function
err_grd <- seq(-1,1,length.out=200)
plot(err_grd, custom_loss(err_grd,0), type='l',
xlab='y-yhat', ylab='custom loss')
## fit linear model with custom loss
lin_beta_custom <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=custom_loss)
lin_pred_custom <- predict_lin(x=x_grid, beta=lin_beta_custom$par)
## plot data
plot_psa_data()
## plot predictions from L2 loss
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
## plot predictions from custom loss
lines(x=x_grid, y=lin_pred_custom, col='pink', lwd=2, lty=2)
absolute_loss_function <- function(y,yhat){
abs(y-yhat)
}
abs_beta <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function)
abs_pred <- predict_lin(x=x_grid, beta=abs_beta$par)
plot_psa_data()
title = (main = "Linear prediction")
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
lines(x=x_grid, y=abs_pred, col='pink', lwd=2)
legend("bottomright", legend = c("L2_loss", "L1_loss"),col = c("darkgreen","pink"), lty  = 1)
nonlinear_pred <- function(x,beta){
beta[1] + beta[2]*exp(-beta[3]*x)
}
fit_nonlin <- function(y, x, loss=L2_loss, beta_init = c(-1.0, 0.0, -0.3), predict_fun = nonlinear_pred){
err <- function(beta)
mean(loss(y,  predict_lin(x,beta)))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
L1_non_pred_beta <- fit_nonlin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=absolute_loss_function,
beta_init = c(-1.0, 0.0, -0.3),
predict_fun = nonlinear_pred)
L2_non_pred_beta <- fit_nonlin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=L2_loss,
beta_init = c(-1.0, 0.0, -0.3),
predict_fun = nonlinear_pred)
L1_non_pred <- nonlinear_pred(x=x_grid, beta=L1_non_pred_beta$par)
L2_non_pred <- nonlinear_pred(x=x_grid, beta=L2_non_pred_beta$par)
plot_psa_data()
title(main = "Nonlinear prediction")
## plot predictions from L2 loss
lines(x=x_grid, y=L1_non_pred, col='darkgreen', lwd=2)
## plot predictions from custom loss
lines(x=x_grid, y=L2_non_pred, col='pink', lwd=2)
legend("bottomright", "(x,y)", legend = c("L1_Loss", "L2_loss"), col = c("darkgreen", "pink"),lwd = 1)
absolute_loss_function <- function(y,yhat,tau){
if ((y-yhat) > 0){
tau * (y-yhat)
}else{
(tau-1) * (y-yhat)
}
}
install.packages(qrnn)
install.packages("qrnn")
abs_beta <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function())
absolute_loss_function <- function(y,yhat,tau){
if ((y-yhat) > 0){
tau*(y-yhat)
}else{
(tau-1)*(y-yhat)
}
}
absolute_loss_function <- function(y,yhat,tau){
if ((y-yhat) > 0){
tau*(y-yhat)
}else{
(tau-1)*(y-yhat)
}
}
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
abs_pred <- predict_lin(x=x_grid, beta=abs_beta$par)
plot_psa_data()
title = (main = "Linear prediction")
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
lines(x=x_grid, y=abs_pred, col='pink', lwd=2)
legend("bottomright", legend = c("L2_loss", "L1_loss"),col = c("darkgreen","pink"), lty  = 1)
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(titled(loss(y,  predict_lin(x,beta)),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
library("qrnn")
## load prostate data
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
library("qrnn")
## load prostate data
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
library("qrnn")
## load prostate data
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
## subset to training examples
prostate_train <- subset(prostate, train==TRUE)
## plot lcavol vs lpsa
plot_psa_data <- function(dat=prostate_train) {
plot(dat$lpsa, dat$lcavol,
xlab="log Prostate Screening Antigen (psa)",
ylab="log Cancer Volume (lcavol)",
pch = 20)
}
plot_psa_data()
############################
## regular linear regression
############################
## L2 loss function
L2_loss <- function(y, yhat)
(y-yhat)^2
## fit simple linear model using numerical optimization
predict_lin <- function(x, beta){
beta[1] + beta[2]*x
}
fit_lin <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta)))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
## make predictions from linear model
## fit linear model
lin_beta <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=L2_loss)
## compute predictions for a grid of inputs
x_grid <- seq(min(prostate_train$lpsa),
max(prostate_train$lpsa),
length.out=100)
lin_pred <- predict_lin(x=x_grid, beta=lin_beta$par)
## plot data
plot_psa_data()
## plot predictions
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
## do the same thing with 'lm'
lin_fit_lm <- lm(lcavol ~ lpsa, data=prostate_train)
## make predictins using 'lm' object
lin_pred_lm <- predict(lin_fit_lm, data.frame(lpsa=x_grid))
## plot predictions from 'lm'
lines(x=x_grid, y=lin_pred_lm, col='pink', lty=2, lwd=2)
##################################
## try modifying the loss function
##################################
## custom loss function
custom_loss <- function(y, yhat){
(y-yhat)^2 + abs(y-yhat)
}
## plot custom loss function
err_grd <- seq(-1,1,length.out=200)
plot(err_grd, custom_loss(err_grd,0), type='l',
xlab='y-yhat', ylab='custom loss')
## fit linear model with custom loss
lin_beta_custom <- fit_lin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=custom_loss)
lin_pred_custom <- predict_lin(x=x_grid, beta=lin_beta_custom$par)
## plot data
plot_psa_data()
## plot predictions from L2 loss
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
## plot predictions from custom loss
lines(x=x_grid, y=lin_pred_custom, col='pink', lwd=2, lty=2)
absolute_loss_function <- function(y,yhat){
absy-yhat)
absolute_loss_function <- function(y,yhat){
abs(y-yhat)
}
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(titled.abs(loss(y,  predict_lin(x,beta)),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(qrnn::titled.abs(loss(y,  predict_lin(x,beta)),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
library("qrnn")
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(titled.abs(loss(y,  predict_lin(x,beta)),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
absolute_loss_function <- function(y,yhat,tau){
tilted.abs(y-yhat,tau)
}
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta,tau)))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
abs_pred <- predict_lin(x=x_grid, beta=abs_beta$par)
plot_psa_data()
title = (main = "Linear prediction")
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
lines(x=x_grid, y=abs_pred, col='pink', lwd=2)
legend("bottomright", legend = c("L2_loss", "L1_loss"),col = c("darkgreen","pink"), lty  = 1)
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta_25 <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
abs_beta_75 <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
abs_pred_25 <- predict_lin(x=x_grid, beta=abs_beta_25$par)
abs_pred_75 <- predict_lin(x=x_grid, beta=abs_beta_75$par)
plot_psa_data()
title = (main = "Linear prediction")
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
lines(x=x_grid, y=abs_pred_25, col='pink', lwd=2)
lines(x=x_grid, y=abs_pred_75, col='blue', lwd=2)
legend("bottomright", legend = c("L2_loss", "L1_loss_tau=0.25", "L1_loss_tau=0.75"),col = c("darkgreen","pink","blue"), lty  = 1)
fit_lin_new <- function(y, x, loss=L2_loss, beta_init = c(-0.51, 0.75), predict_fun = predict_lin,tau = 0.5) {
err <- function(beta)
mean(loss(y,  predict_lin(x,beta),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
abs_beta_25 <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.25)
abs_beta_75 <- fit_lin_new(y=prostate_train$lcavol,
x=prostate_train$lpsa,
beta_init = c(-0.51, 0.75),
loss= absolute_loss_function,
tau = 0.75)
abs_pred_25 <- predict_lin(x=x_grid, beta=abs_beta_25$par)
abs_pred_75 <- predict_lin(x=x_grid, beta=abs_beta_75$par)
plot_psa_data()
title = (main = "Linear prediction")
lines(x=x_grid, y=lin_pred, col='darkgreen', lwd=2)
lines(x=x_grid, y=abs_pred_25, col='pink', lwd=2)
lines(x=x_grid, y=abs_pred_75, col='blue', lwd=2)
legend("bottomright", legend = c("L2_loss", "L1_loss_tau=0.25", "L1_loss_tau=0.75"),col = c("darkgreen","pink","blue"), lty  = 1)
nonlinear_pred <- function(x,beta){
beta[1] + beta[2]*exp(-beta[3]*x)
}
fit_nonlin <- function(y, x, loss=L2_loss, beta_init = c(-1.0, 0.0, -0.3), predict_fun = nonlinear_pred){
err <- function(beta)
mean(loss(y,  predict_lin(x,beta)))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
fit_nonlin_abs <- function(y, x, loss=L2_loss, beta_init = c(-1.0, 0.0, -0.3), predict_fun = nonlinear_pred,tau){
err <- function(beta)
mean(loss(y,  predict_lin(x,beta),tau))
beta <- optim(par = beta_init, fn = err)
return(beta)
}
L1_non_pred_beta_25 <- fit_nonlin_abs(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=absolute_loss_function,
beta_init = c(-1.0, 0.0, -0.3),
predict_fun = nonlinear_pred,tau = 0.25)
L1_non_pred_beta_75 <- fit_nonlin_abs(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=absolute_loss_function,
beta_init = c(-1.0, 0.0, -0.3),
predict_fun = nonlinear_pred,tau = 0.75)
L2_non_pred_beta <- fit_nonlin(y=prostate_train$lcavol,
x=prostate_train$lpsa,
loss=L2_loss,
beta_init = c(-1.0, 0.0, -0.3),
predict_fun = nonlinear_pred)
L1_non_pred_25 <- nonlinear_pred(x=x_grid, beta=L1_non_pred_beta_25$par)
L1_non_pred_75 <- nonlinear_pred(x=x_grid, beta=L1_non_pred_beta_75$par)
L2_non_pred <- nonlinear_pred(x=x_grid, beta=L2_non_pred_beta$par)
plot_psa_data()
title(main = "Nonlinear prediction")
## plot predictions from L2 loss
lines(x=x_grid, y=L1_non_pred_25, col='darkgreen', lwd=2)
lines(x=x_grid, y=L1_non_pred_75, col='blue', lwd=2)
## plot predictions from custom loss
lines(x=x_grid, y=L2_non_pred, col='pink', lwd=2)
legend("bottomright", "(x,y)", legend = c("L1_Loss_tau = 0.25","L1_Loss_tau = 0.75", "L2_loss"), col = c("darkgreen","blue", "pink"),lwd = 1)
